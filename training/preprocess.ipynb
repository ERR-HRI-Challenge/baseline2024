{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#remove warnings\n",
    "import warnings\n",
    "#ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fold-subject-independent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24_train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38_train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51_train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11_train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  fold-subject-independent\n",
       "0  10_train                         1\n",
       "1  24_train                         1\n",
       "2  38_train                         1\n",
       "3  51_train                         1\n",
       "4  11_train                         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#open the csv with labels\n",
    "\n",
    "fold_set = pd.read_csv('../dataset/fold_split.csv')\n",
    "fold_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick check: open the files for every feature folder, and check if the columns are the same and check for empty columns\n",
    "\n",
    "#now, open the sessions on train_val\n",
    "\n",
    "#open train_val folder\n",
    "\n",
    "label_path = '../../data/train_val/labels'\n",
    "data_path = '../../data/train_val/'\n",
    "\n",
    "#list files in path\n",
    "files = os.listdir(label_path)\n",
    "#remove hidden files\n",
    "files = [file for file in files if not file.startswith('.')]\n",
    "\n",
    "print('Number of sessions:', len(files))\n",
    "\n",
    "\n",
    "#open each feature folder, get the csvs into a single dataframe, with the session number as a column\n",
    "feature_folders = ['openface', 'openpose', 'opensmile']\n",
    "\n",
    "for folder in feature_folders:\n",
    "    print('Processing', folder)\n",
    "    #list files in path\n",
    "    files = os.listdir(data_path + folder)\n",
    "    #remove hidden files\n",
    "    files = [file for file in files if not file.startswith('.')]\n",
    "    columns = [] \n",
    "    for file in files:\n",
    "        #open the first file to get the column names\n",
    "        df = pd.read_csv(data_path + folder + '/' + file)\n",
    "        #add column with session number\n",
    "        session= file.split('.')[0]\n",
    "        if len(columns) == 0:\n",
    "            columns = df.columns\n",
    "            data = df\n",
    "        else:\n",
    "            cols = df.columns\n",
    "            if not all(elem in columns for elem in cols):\n",
    "                print('Columns do not match')\n",
    "                print('Columns in', folder, 'not in data:', [elem for elem in cols if elem not in columns])\n",
    "                print(session)\n",
    "        #now, check for completely empty columns\n",
    "        empty_cols = df.columns[df.isnull().all()]\n",
    "        if len(empty_cols) > 0:\n",
    "            print('Empty columns in', folder, ':', empty_cols)\n",
    "            print(session)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, open the sessions on train_val\n",
    "\n",
    "#open train_val folder\n",
    "\n",
    "label_path = '../../data/train_val/labels'\n",
    "data_path = '../../data/train_val/'\n",
    "\n",
    "#list files in path\n",
    "files = os.listdir(label_path)\n",
    "#remove hidden files\n",
    "files = [file for file in files if not file.startswith('.')]\n",
    "\n",
    "print('Number of sessions:', len(files))\n",
    "\n",
    "\n",
    "#open each feature folder, get the csvs into a single dataframe, with the session number as a column\n",
    "feature_folders = ['openface', 'openpose', 'opensmile']\n",
    "\n",
    "#initialize the dataframe\n",
    "#check if the file exists\n",
    "if os.path.exists('../../data/train_val.csv'):\n",
    "    train_val = pd.read_csv('../../data/train_val.csv')\n",
    "    print('train_val:', train_val.shape)\n",
    "    sessions_already = train_val['session'].unique()\n",
    "else:\n",
    "    train_val = pd.DataFrame()\n",
    "    sessions_already = []\n",
    "\n",
    "#save session names when there is a difference for time and frames\n",
    "diff_session = dict()\n",
    "    \n",
    "#get session names\n",
    "files_folders = os.listdir(data_path + feature_folders[0])\n",
    "sessions = [file.split('.')[0] for file in files_folders if not file.startswith('.')]\n",
    "for session in sessions:\n",
    "    print('session:', session)\n",
    "    if session in sessions_already:\n",
    "        print('session already in train_val')\n",
    "        continue\n",
    "    for folder in feature_folders:\n",
    "        \n",
    "        #if folder openface\n",
    "        if folder == 'openface':\n",
    "            #get the csv\n",
    "            session_csv = pd.read_csv(data_path + folder + '/' + session + '.csv')\n",
    "            #if empty, skip this session\n",
    "            if session_csv.empty:\n",
    "                print('empty openface')\n",
    "                continue\n",
    "\n",
    "            #remove rows with nan values\n",
    "            print('openface prenan:', session_csv.shape)\n",
    "            session_csv.dropna(inplace=True)\n",
    "            print('openface postnan:', session_csv.shape)\n",
    "            #add session column as the first column\n",
    "\n",
    "            #decrease the frame by one\n",
    "            session_csv['frame'] = session_csv['frame'] - 1\n",
    "            session_csv['session'] = session\n",
    "            #change session from last to first column\n",
    "            cols = session_csv.columns.tolist()\n",
    "            cols = cols[-1:] + cols[:-1]\n",
    "            session_csv = session_csv[cols]\n",
    "            #change [' timestamp'] to timestamp\n",
    "            session_csv.rename(columns={' timestamp': 'timestamp'}, inplace=True)\n",
    "            print('openface:', session_csv.shape)\n",
    "            #print(session_csv.columns)\n",
    "            #print(session_csv.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #if folder openpose\n",
    "        if folder == 'openpose':\n",
    "            #get the csv\n",
    "            open_csv = pd.read_csv(data_path + folder + '/' + session + '.csv')\n",
    "            #if empty, skip this session\n",
    "            if open_csv.empty:\n",
    "                print('empty openpose')\n",
    "                continue\n",
    "            #reduce one in frame_id\n",
    "            open_csv['frame_id'] = open_csv['frame_id']\n",
    "            #remove columns ['person_id', 'week_id', 'robot_group'] if existing\n",
    "            if 'person_id' in open_csv.columns:\n",
    "                open_csv.drop(columns=['person_id', 'week_id', 'robot_group'], inplace=True)\n",
    "\n",
    "            #remove columns ['vel_1_x', 'vel_1_y', 'vel_8_x', 'vel_8_y', 'dist_1_8', 'vel_dist_1_8', 'dist_7_0', 'dist_4_0', 'vel_7_x', 'vel_7_y', 'vel_4_x', 'vel_4_y','vel_dist_7_0', 'vel_dist_4_0']\n",
    "            if 'vel_1_x' in open_csv.columns:\n",
    "                open_csv.drop(columns=['vel_1_x', 'vel_1_y', 'vel_8_x', 'vel_8_y', 'dist_1_8', 'vel_dist_1_8', \n",
    "                                       'dist_7_0', 'dist_4_0', 'vel_7_x', 'vel_7_y', 'vel_4_x', 'vel_4_y',\n",
    "                                       'vel_dist_7_0', 'vel_dist_4_0'], inplace=True)\n",
    "            #see difference in index numbers\n",
    "            #index_session = session_csv['frame'].values\n",
    "            #index_open = open_csv['frame_id'].values\n",
    "            #print('openpose:', index_session, index_open)\n",
    "            #see if they are the same, if not print\n",
    "            #if not np.array_equal(index_session, index_open):\n",
    "            #    print('Different indexes')\n",
    "            #    #which are different\n",
    "            #    diff = np.where(index_session != index_open)\n",
    "            #    print(diff)\n",
    "\n",
    "            #remove rows with nan values\n",
    "            print('openpose prenan:', open_csv.shape)\n",
    "            open_csv.dropna(inplace=True)\n",
    "            print('openpose postnan:', open_csv.shape)\n",
    "\n",
    "            #merge horizontally with the session_csv, through column \"frame_id\" and \"frame\" in open_csv and session_csv, respectively\n",
    "            session_csv = pd.merge(session_csv, open_csv, how='inner', left_on='frame', right_on='frame_id')\n",
    "            #drop the frame_id column\n",
    "            session_csv.drop(columns='frame_id', inplace=True)\n",
    "\n",
    "            print('openpose prenan:', session_csv.shape)\n",
    "            session_csv.dropna(inplace=True)\n",
    "            print('openpose postnan:', session_csv.shape)\n",
    "\n",
    "            print('openpose:', session_csv.shape)\n",
    "            #print(session_csv.columns)\n",
    "            #print(session_csv.head())\n",
    "\n",
    "        #if folder opensmile\n",
    "        if folder == 'opensmile':\n",
    "            #get the csv\n",
    "            smile_csv = pd.read_csv(data_path + folder + '/' + session + '.csv')\n",
    "            if smile_csv.empty:\n",
    "                print('empty opensmile')\n",
    "                continue\n",
    "\n",
    "            #now, open the corresponding speaker_diarization file\n",
    "            sd_path = '../../data/train_val/speaker_diarization/'\n",
    "            sd_csv = pd.read_csv(sd_path + session + '.csv')\n",
    "            #if empty, skip this session\n",
    "            if sd_csv.empty:\n",
    "                print('empty speaker diarization')\n",
    "                print('***************************************************************************')\n",
    "                continue\n",
    "\n",
    "            print('opensmile prenan:', smile_csv.shape)\n",
    "            smile_csv.dropna(inplace=True)\n",
    "            print('opensmile postnan:', smile_csv.shape)\n",
    "\n",
    "            #drop column \"file\"\n",
    "            if 'Unnamed: 0' in smile_csv.columns:\n",
    "                smile_csv.drop(columns='Unnamed: 0', inplace=True)\n",
    "                \n",
    "\n",
    "\n",
    "            #time is as \"0 days 00:00:02.510000\"\n",
    "            #turn this into only seconds - 2.51\n",
    "            #first, turn into time instead of string\n",
    "            smile_csv['start'] = pd.to_timedelta(smile_csv['start'])\n",
    "            #print(smile_csv[['start']].head())\n",
    "            smile_csv['time'] = smile_csv['start'].apply(lambda x: x.total_seconds())\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            #print(smile_csv['time']) \n",
    "            #print(session_csv.columns)\n",
    "            subset_smile = pd.DataFrame()\n",
    "            #go row by row in session_csv, and look at timestamp. use the timestamp column as a reference to get the opensmile features, and get the average of the features in opensmile within the interval\n",
    "            prev_time = 0   \n",
    "            for ind, row in session_csv.iterrows():\n",
    "                #get the timestamp\n",
    "                timestamp = row['frame']/30 #in seconds, for 30 fps\n",
    "                #if timestamp is 0, then avg_features is the first row of smile_csv\n",
    "                if timestamp == 0:\n",
    "                    avg_features = smile_csv.iloc[0]\n",
    "                    avg_features['time'] = timestamp\n",
    "                    #drop start and end columns\n",
    "                    avg_features.drop(['start', 'end'], inplace=True)\n",
    "                    subset_smile = pd.concat([subset_smile, avg_features], axis=1)\n",
    "                    prev_time = 0\n",
    "                    continue\n",
    "\n",
    "\n",
    "                #get the opensmile features that are in the interval\n",
    "                interval = smile_csv[(smile_csv['time'] > prev_time) & (smile_csv['time'] <= timestamp)]\n",
    "\n",
    "                #now, check who was speaking. Column \"speaker\" in sd_csv is robot, person or pause. time is in seconds, and there are two columns, start_turn and end_turn\n",
    "                #if the timestamp is within the interval of a speaker, then keep the interval, otherwise, zero out the features\n",
    "                speaker = sd_csv[(sd_csv['start_turn'] <= timestamp) & (sd_csv['end_turn'] > timestamp)]['speaker']\n",
    "                if speaker.empty:\n",
    "                    speaker = pd.DataFrame(['pause'])\n",
    "                #    print(timestamp, 'empty speaker')\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "                #if empty, print warning\n",
    "                if interval.empty:\n",
    "                    if timestamp > smile_csv['time'].max():\n",
    "                        print('timestamp is bigger than max time')\n",
    "                        print('timestamp max:', session_csv['frame'].max()/30, 'max time opensmile:', smile_csv['time'].max())\n",
    "                        diff_session[session] = (session_csv['frame'].max()/30, smile_csv['time'].max())\n",
    "                    else:\n",
    "                        print('empty interval')\n",
    "                    #skip rest of the loop\n",
    "                    break\n",
    "\n",
    "\n",
    "                #print(interval)\n",
    "                interval['time'] = timestamp\n",
    "                interval['frame'] = row['frame']\n",
    "                #remove start and end columns\n",
    "                interval.drop(columns=['start', 'end'], inplace=True)\n",
    "                #get the average of the features\n",
    "                if speaker.values[0] == 'participant':\n",
    "                    avg_features = interval.mean()\n",
    "                else:\n",
    "                    avg_features = interval.mean()\n",
    "                    avg_features[:] = 0\n",
    "            \n",
    "                avg_features['time'] = timestamp\n",
    "                avg_features['frame'] = row['frame']\n",
    "                #avg_features['speaker'] = speaker.values[0]\n",
    "                #print(speaker.values[0])\n",
    "                #print(avg_features)\n",
    "                #append the features to the subset_smile\n",
    "                subset_smile = pd.concat([subset_smile, avg_features], axis=1)\n",
    "                #print(subset_smile.shape)\n",
    "                #update the prev_time\n",
    "                prev_time = timestamp\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            print('done')\n",
    "            #transpose the subset_smile \n",
    "            subset_smile = subset_smile.T\n",
    "            #reindex\n",
    "            subset_smile.reset_index(drop=True, inplace=True)\n",
    "            print(subset_smile.shape)\n",
    "            \n",
    "            #print(subset_smile.columns)\n",
    "            #print(subset_smile)\n",
    "            #merge horizontally with the session_csv\n",
    "            session_csv = pd.merge(session_csv, subset_smile, how='inner', left_on='frame', right_on='frame')\n",
    "\n",
    "\n",
    "            print('opensmile:', session_csv.shape)\n",
    "            #print(session_csv.head())\n",
    "            \n",
    "        \n",
    "    #add a column with fold_id to the session_csv\n",
    "    fold_id = fold_set[fold_set['id'] == session]['fold-subject-independent'].values[0]\n",
    "    session_csv['fold_id'] = fold_id\n",
    "    print('fold_id:', fold_id)\n",
    "    \n",
    "    #append the session_csv to the train_val\n",
    "    train_val = pd.concat([train_val, session_csv], axis=0)\n",
    "    print('train_val:', train_val.shape)\n",
    "    print('train_val columns:', train_val.columns)\n",
    "    train_val.reset_index(drop=True, inplace=True)\n",
    "    #save the train_val\n",
    "    train_val.to_csv('../../data/train_val.csv', index=False)\n",
    "\n",
    "    print('DIFF SESSION:', diff_session)    \n",
    "\n",
    "\n",
    "train_val.reset_index(drop=True, inplace=True)\n",
    "print(train_val.shape)\n",
    "#save the train_val\n",
    "train_val.to_csv('../../data/train_val.csv', index=False)\n",
    "train_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open train_val folder\n",
    "train_val = pd.read_csv('../../data/train_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove time column\n",
    "train_val.drop(columns='timestamp', inplace=True)\n",
    "#make fold_id the first column\n",
    "cols = train_val.columns.tolist()   \n",
    "cols = cols[-2:] + cols[:-2]\n",
    "train_val = train_val[cols]\n",
    "print(train_val.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do NOT USE\n",
    "\n",
    "#get labels for each session, add to the train_val\n",
    "\n",
    "#label folder\n",
    "label_path = '../../data/train_val/labels/'\n",
    "#list files in path\n",
    "files = os.listdir(label_path)\n",
    "#remove hidden files\n",
    "files = [file for file in files if not file.startswith('.')]\n",
    "print('Number of sessions:', len(files))\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    #open the csv\n",
    "    label_df = pd.read_csv(label_path + file)\n",
    "    #get the session number\n",
    "    session = file.split('.')[0]\n",
    "    if session in train_val['session'].values:\n",
    "        #get the label\n",
    "        train_val_session = train_val[train_val['session'] == session]\n",
    "    else:\n",
    "        print('Session NOT in train_val:', session)\n",
    "        continue\n",
    "\n",
    "    #for each row in train_val_session, get the time, and match it to the time in the label dataset\n",
    "    #if the time is within the interval, get the label\n",
    "    for ind,row in train_val_session.iterrows():\n",
    "        time = row['time']\n",
    "        #get the label\n",
    "        label_row = label_df[(label_df['Begin Time - ss.msec'] <= time) & (label_df['End Time - ss.msec'] >= time)]\n",
    "        if label_row.empty:\n",
    "            print('empty label')\n",
    "            print('time:', time)\n",
    "            print('session:', session)\n",
    "            label_column_0.append('NaN')\n",
    "            label_column_1.append('NaN')\n",
    "            label_column_2.append('NaN')\n",
    "        else:\n",
    "            label_column_0.append(label_row['UserAwkwardness'].values[0])\n",
    "            label_column_1.append(label_row['RobotMistake'].values[0])\n",
    "            label_column_2.append(label_row['InteractionRupture'].values[0])\n",
    "    \n",
    "#add the labels to the train_val, as columns 3-5\n",
    "train_val['UserAwkwardness'] = label_column_0\n",
    "train_val['RobotMistake'] = label_column_1\n",
    "train_val['InteractionRupture'] = label_column_2\n",
    "cols_df = train_val.columns.tolist()\n",
    "cols_df_new = cols_df[:4] + cols_df[-3:] + cols_df[4:-3]\n",
    "\n",
    "train_val = train_val[cols_df_new]\n",
    "print(train_val.columns)\n",
    "print(train_val.shape)\n",
    "train_val.to_csv('../../data/train_val.csv', index=False)\n",
    "train_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get labels for each session, add to the train_val\n",
    "\n",
    "#get train_val\n",
    "train_val = pd.read_csv('../../data/train_val.csv')\n",
    "#make the 3 label columns zeros\n",
    "train_val['UserAwkwardness'] = 0\n",
    "train_val['RobotMistake'] = 0\n",
    "train_val['InteractionRupture'] = 0\n",
    "\n",
    "#label folder\n",
    "label_path = '../../data/train_val/labels/'\n",
    "#list files in path\n",
    "files = os.listdir(label_path)\n",
    "#remove hidden files\n",
    "files = [file for file in files if not file.startswith('.')]\n",
    "print('Number of sessions:', len(files))\n",
    "\n",
    "label_column_0 = []\n",
    "label_column_1 = []\n",
    "label_column_2 = []\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    #open the csv\n",
    "    label_df = pd.read_csv(label_path + file)\n",
    "    #get the session number\n",
    "    session = file.split('.')[0]\n",
    "    if session in train_val['session'].values:\n",
    "        #get the label\n",
    "        train_val_session = train_val[train_val['session'] == session]\n",
    "    else:\n",
    "        print('Session NOT in train_val:', session)\n",
    "        continue\n",
    "\n",
    "    #for each row in train_val_session, get the time, and match it to the time in the label dataset\n",
    "    #if the time is within the interval, get the label\n",
    "    for ind,row in label_df.iterrows():\n",
    "        time_min = row['Begin Time - ss.msec']\n",
    "        time_max = row['End Time - ss.msec']\n",
    "        #get labels for each\n",
    "        lab_uawk = row['UserAwkwardness']\n",
    "        lab_rmist = row['RobotMistake']\n",
    "        lab_irupt = row['InteractionRupture']\n",
    "        #get the rows in train_val_session that are within the interval\n",
    "        train_val_interval = train_val_session[(train_val_session['time'] >= time_min) & (train_val_session['time'] <= time_max)]\n",
    "        #get the indexes\n",
    "        index_interval = train_val_interval.index\n",
    "        print('lenght of train_val_interval:', len(train_val_interval))\n",
    "        print('index_interval:', index_interval)\n",
    "        if len(train_val_interval) == 0:\n",
    "            print('empty interval')\n",
    "            print('time_min:', time_min)\n",
    "            print('time_max:', time_max)\n",
    "            print('session:', session)\n",
    "        else:\n",
    "            if lab_uawk == 1:\n",
    "                train_val.loc[index_interval, 'UserAwkwardness'] = lab_uawk\n",
    "            if lab_rmist == 1:\n",
    "                train_val.loc[index_interval, 'RobotMistake'] = lab_rmist\n",
    "            if lab_irupt == 1:\n",
    "                train_val.loc[index_interval, 'InteractionRupture'] = lab_irupt\n",
    "\n",
    "\n",
    "\n",
    "train_val.to_csv('../../data/train_val.csv', index=False)\n",
    "train_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now normalize features\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#copy dataframe\n",
    "train_val_norm = train_val.copy()\n",
    "#normalize features\n",
    "scaler = StandardScaler()\n",
    "features = train_val_norm.columns[7:]\n",
    "print(features)\n",
    "train_val_norm[features] = scaler.fit_transform(train_val_norm[features])\n",
    "\n",
    "#remove nan and inf\n",
    "train_val_norm.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "train_val_norm.dropna(inplace=True)\n",
    "\n",
    "train_val_norm.to_csv('../../data/train_val_norm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../data/scaler.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the scaler\n",
    "import joblib\n",
    "joblib.dump(scaler, '../../data/scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#remove warnings\n",
    "import warnings\n",
    "#ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick check: open the files for every feature folder, and check if the columns are the same and check for empty columns\n",
    "\n",
    "#now, open the sessions on train_val\n",
    "\n",
    "#open train_val folder\n",
    "\n",
    "label_path = '../../data/test/labels'\n",
    "data_path = '../../data/test/'\n",
    "\n",
    "#list files in path\n",
    "files = os.listdir(label_path)\n",
    "#remove hidden files\n",
    "files = [file for file in files if not file.startswith('.')]\n",
    "\n",
    "print('Number of sessions:', len(files))\n",
    "\n",
    "\n",
    "#open each feature folder, get the csvs into a single dataframe, with the session number as a column\n",
    "feature_folders = ['openface', 'openpose', 'opensmile']\n",
    "\n",
    "for folder in feature_folders:\n",
    "    print('Processing', folder)\n",
    "    #list files in path\n",
    "    files = os.listdir(data_path + folder)\n",
    "    #remove hidden files\n",
    "    files = [file for file in files if not file.startswith('.')]\n",
    "    columns = [] \n",
    "    for file in files:\n",
    "        #open the first file to get the column names\n",
    "        df = pd.read_csv(data_path + folder + '/' + file)\n",
    "        #add column with session number\n",
    "        session= file.split('.')[0]\n",
    "        if len(columns) == 0:\n",
    "            columns = df.columns\n",
    "            data = df\n",
    "        else:\n",
    "            cols = df.columns\n",
    "            if not all(elem in columns for elem in cols):\n",
    "                print('Columns do not match')\n",
    "                print('Columns in', folder, 'not in data:', [elem for elem in cols if elem not in columns])\n",
    "                print(session)\n",
    "        #now, check for completely empty columns\n",
    "        empty_cols = df.columns[df.isnull().all()]\n",
    "        if len(empty_cols) > 0:\n",
    "            print('Empty columns in', folder, ':', empty_cols)\n",
    "            print(session)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, open the sessions on train_val\n",
    "\n",
    "#open train_val folder\n",
    "\n",
    "label_path = '../../data/test/labels'\n",
    "data_path = '../../data/test/'\n",
    "\n",
    "#list files in path\n",
    "files = os.listdir(label_path)\n",
    "#remove hidden files\n",
    "files = [file for file in files if not file.startswith('.')]\n",
    "\n",
    "print('Number of sessions:', len(files))\n",
    "\n",
    "\n",
    "#open each feature folder, get the csvs into a single dataframe, with the session number as a column\n",
    "feature_folders = ['openface', 'openpose', 'opensmile']\n",
    "\n",
    "#initialize the dataframe\n",
    "#check if the file exists\n",
    "if os.path.exists('../../data/test.csv'):\n",
    "    train_val = pd.read_csv('../../data/test.csv')\n",
    "    print('train_val:', train_val.shape)\n",
    "    sessions_already = train_val['session'].unique()\n",
    "else:\n",
    "    train_val = pd.DataFrame()\n",
    "    sessions_already = []\n",
    "\n",
    "#save session names when there is a difference for time and frames\n",
    "diff_session = dict()\n",
    "    \n",
    "#get session names\n",
    "files_folders = os.listdir(data_path + feature_folders[0])\n",
    "sessions = [file.split('.')[0] for file in files_folders if not file.startswith('.')]\n",
    "for session in sessions:\n",
    "    print('session:', session)\n",
    "    if session in sessions_already:\n",
    "        print('session already in train_val')\n",
    "        continue\n",
    "    for folder in feature_folders:\n",
    "        \n",
    "        #if folder openface\n",
    "        if folder == 'openface':\n",
    "            #get the csv\n",
    "            session_csv = pd.read_csv(data_path + folder + '/' + session + '.csv')\n",
    "            #if empty, skip this session\n",
    "            if session_csv.empty:\n",
    "                print('empty openface')\n",
    "                continue\n",
    "\n",
    "            #remove rows with nan values\n",
    "            print('openface prenan:', session_csv.shape)\n",
    "            session_csv.dropna(inplace=True)\n",
    "            print('openface postnan:', session_csv.shape)\n",
    "            #add session column as the first column\n",
    "\n",
    "            #decrease the frame by one\n",
    "            session_csv['frame'] = session_csv['frame'] - 1\n",
    "            session_csv['session'] = session\n",
    "            #change session from last to first column\n",
    "            cols = session_csv.columns.tolist()\n",
    "            cols = cols[-1:] + cols[:-1]\n",
    "            session_csv = session_csv[cols]\n",
    "            #change [' timestamp'] to timestamp\n",
    "            session_csv.rename(columns={' timestamp': 'timestamp'}, inplace=True)\n",
    "            print('openface:', session_csv.shape)\n",
    "            #print(session_csv.columns)\n",
    "            #print(session_csv.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #if folder openpose\n",
    "        if folder == 'openpose':\n",
    "            #get the csv\n",
    "            open_csv = pd.read_csv(data_path + folder + '/' + session + '.csv')\n",
    "            #if empty, skip this session\n",
    "            if open_csv.empty:\n",
    "                print('empty openpose')\n",
    "                continue\n",
    "            #reduce one in frame_id\n",
    "            open_csv['frame_id'] = open_csv['frame_id']\n",
    "            #remove columns ['person_id', 'week_id', 'robot_group'] if existing\n",
    "            if 'person_id' in open_csv.columns:\n",
    "                open_csv.drop(columns=['person_id', 'week_id', 'robot_group'], inplace=True)\n",
    "\n",
    "            #remove columns ['vel_1_x', 'vel_1_y', 'vel_8_x', 'vel_8_y', 'dist_1_8', 'vel_dist_1_8', 'dist_7_0', 'dist_4_0', 'vel_7_x', 'vel_7_y', 'vel_4_x', 'vel_4_y','vel_dist_7_0', 'vel_dist_4_0']\n",
    "            if 'vel_1_x' in open_csv.columns:\n",
    "                open_csv.drop(columns=['vel_1_x', 'vel_1_y', 'vel_8_x', 'vel_8_y', 'dist_1_8', 'vel_dist_1_8', \n",
    "                                       'dist_7_0', 'dist_4_0', 'vel_7_x', 'vel_7_y', 'vel_4_x', 'vel_4_y',\n",
    "                                       'vel_dist_7_0', 'vel_dist_4_0'], inplace=True)\n",
    "\n",
    "\n",
    "            #remove rows with nan values\n",
    "            print('openpose prenan:', open_csv.shape)\n",
    "            open_csv.dropna(inplace=True)\n",
    "            print('openpose postnan:', open_csv.shape)\n",
    "\n",
    "            #merge horizontally with the session_csv, through column \"frame_id\" and \"frame\" in open_csv and session_csv, respectively\n",
    "            session_csv = pd.merge(session_csv, open_csv, how='inner', left_on='frame', right_on='frame_id')\n",
    "            #drop the frame_id column\n",
    "            session_csv.drop(columns='frame_id', inplace=True)\n",
    "\n",
    "            print('openpose prenan:', session_csv.shape)\n",
    "            session_csv.dropna(inplace=True)\n",
    "            print('openpose postnan:', session_csv.shape)\n",
    "\n",
    "            print('openpose:', session_csv.shape)\n",
    "            #print(session_csv.columns)\n",
    "            #print(session_csv.head())\n",
    "\n",
    "        #if folder opensmile\n",
    "        if folder == 'opensmile':\n",
    "            #get the csv\n",
    "            smile_csv = pd.read_csv(data_path + folder + '/' + session + '.csv')\n",
    "            if smile_csv.empty:\n",
    "                print('empty opensmile')\n",
    "                continue\n",
    "\n",
    "            #now, open the corresponding speaker_diarization file\n",
    "            sd_path = '../../data/test/speaker_diarization/'\n",
    "            sd_csv = pd.read_csv(sd_path + session + '.csv')\n",
    "            #if empty, skip this session\n",
    "            if sd_csv.empty:\n",
    "                print('empty speaker diarization')\n",
    "                print('***************************************************************************')\n",
    "                continue\n",
    "\n",
    "            print('opensmile prenan:', smile_csv.shape)\n",
    "            smile_csv.dropna(inplace=True)\n",
    "            print('opensmile postnan:', smile_csv.shape)\n",
    "\n",
    "            #drop column \"file\"\n",
    "            if 'Unnamed: 0' in smile_csv.columns:\n",
    "                smile_csv.drop(columns='Unnamed: 0', inplace=True)\n",
    "                \n",
    "\n",
    "\n",
    "            #time is as \"0 days 00:00:02.510000\"\n",
    "            #turn this into only seconds - 2.51\n",
    "            #first, turn into time instead of string\n",
    "            smile_csv['start'] = pd.to_timedelta(smile_csv['start'])\n",
    "            #print(smile_csv[['start']].head())\n",
    "            smile_csv['time'] = smile_csv['start'].apply(lambda x: x.total_seconds())\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            #print(smile_csv['time']) \n",
    "            #print(session_csv.columns)\n",
    "            subset_smile = pd.DataFrame()\n",
    "            #go row by row in session_csv, and look at timestamp. use the timestamp column as a reference to get the opensmile features, and get the average of the features in opensmile within the interval\n",
    "            prev_time = 0   \n",
    "            for ind, row in session_csv.iterrows():\n",
    "                #get the timestamp\n",
    "                timestamp = row['frame']/30 #in seconds, for 30 fps\n",
    "                #if timestamp is 0, then avg_features is the first row of smile_csv\n",
    "                if timestamp == 0:\n",
    "                    avg_features = smile_csv.iloc[0]\n",
    "                    avg_features['time'] = timestamp\n",
    "                    #drop start and end columns\n",
    "                    avg_features.drop(['start', 'end'], inplace=True)\n",
    "                    subset_smile = pd.concat([subset_smile, avg_features], axis=1)\n",
    "                    prev_time = 0\n",
    "                    continue\n",
    "\n",
    "\n",
    "                #get the opensmile features that are in the interval\n",
    "                interval = smile_csv[(smile_csv['time'] > prev_time) & (smile_csv['time'] <= timestamp)]\n",
    "\n",
    "                #now, check who was speaking. Column \"speaker\" in sd_csv is robot, person or pause. time is in seconds, and there are two columns, start_turn and end_turn\n",
    "                #if the timestamp is within the interval of a speaker, then keep the interval, otherwise, zero out the features\n",
    "                speaker = sd_csv[(sd_csv['start_turn'] <= timestamp) & (sd_csv['end_turn'] > timestamp)]['speaker']\n",
    "                if speaker.empty:\n",
    "                    speaker = pd.DataFrame(['pause'])\n",
    "                #    print(timestamp, 'empty speaker')\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "                #if empty, print warning\n",
    "                if interval.empty:\n",
    "                    if timestamp > smile_csv['time'].max():\n",
    "                        print('timestamp is bigger than max time')\n",
    "                        print('timestamp max:', session_csv['frame'].max()/30, 'max time opensmile:', smile_csv['time'].max())\n",
    "                        diff_session[session] = (session_csv['frame'].max()/30, smile_csv['time'].max())\n",
    "                    else:\n",
    "                        print('empty interval')\n",
    "                    #skip rest of the loop\n",
    "                    break\n",
    "\n",
    "\n",
    "                #print(interval)\n",
    "                interval['time'] = timestamp\n",
    "                interval['frame'] = row['frame']\n",
    "                #remove start and end columns\n",
    "                interval.drop(columns=['start', 'end'], inplace=True)\n",
    "                #get the average of the features\n",
    "                if speaker.values[0] == 'participant':\n",
    "                    avg_features = interval.mean()\n",
    "                else:\n",
    "                    avg_features = interval.mean()\n",
    "                    avg_features[:] = 0\n",
    "            \n",
    "                avg_features['time'] = timestamp\n",
    "                avg_features['frame'] = row['frame']\n",
    "                #avg_features['speaker'] = speaker.values[0]\n",
    "                #print(speaker.values[0])\n",
    "                #print(avg_features)\n",
    "                #append the features to the subset_smile\n",
    "                subset_smile = pd.concat([subset_smile, avg_features], axis=1)\n",
    "                #print(subset_smile.shape)\n",
    "                #update the prev_time\n",
    "                prev_time = timestamp\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "            print('done')\n",
    "            #transpose the subset_smile \n",
    "            subset_smile = subset_smile.T\n",
    "            #reindex\n",
    "            subset_smile.reset_index(drop=True, inplace=True)\n",
    "            print(subset_smile.shape)\n",
    "            \n",
    "            #print(subset_smile.columns)\n",
    "            #print(subset_smile)\n",
    "            #merge horizontally with the session_csv\n",
    "            session_csv = pd.merge(session_csv, subset_smile, how='inner', left_on='frame', right_on='frame')\n",
    "\n",
    "\n",
    "            print('opensmile:', session_csv.shape)\n",
    "            #print(session_csv.head())\n",
    "            \n",
    "        \n",
    "\n",
    "    #append the session_csv to the train_val\n",
    "    train_val = pd.concat([train_val, session_csv], axis=0)\n",
    "    print('train_val:', train_val.shape)\n",
    "    print('train_val columns:', train_val.columns)\n",
    "    train_val.reset_index(drop=True, inplace=True)\n",
    "    #save the train_val\n",
    "    train_val.to_csv('../../data/test.csv', index=False)\n",
    "\n",
    "    print('DIFF SESSION:', diff_session)    \n",
    "\n",
    "\n",
    "train_val.reset_index(drop=True, inplace=True)\n",
    "print(train_val.shape)\n",
    "\n",
    "#save the train_val\n",
    "train_val.to_csv('../../data/test.csv', index=False)\n",
    "train_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove time column\n",
    "train_val.drop(columns='timestamp', inplace=True)\n",
    "#make fold_id the first column\n",
    "cols = train_val.columns.tolist()   \n",
    "cols = cols[-1:] + cols[:-1]\n",
    "train_val = train_val[cols]\n",
    "print(train_val.columns)\n",
    "#save\n",
    "train_val.to_csv('../../data/test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move first column to last\n",
    "cols = train_val.columns.tolist()\n",
    "cols = cols[1:] + cols[:1]\n",
    "train_val = train_val[cols]\n",
    "print(train_val.columns)\n",
    "#save\n",
    "train_val.to_csv('../../data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get labels for each session, add to the train_val\n",
    "\n",
    "#get train_val\n",
    "train_val = pd.read_csv('../../data/test.csv')\n",
    "#make the 3 label columns zeros\n",
    "train_val['UserAwkwardness'] = 0\n",
    "train_val['RobotMistake'] = 0\n",
    "train_val['InteractionRupture'] = 0\n",
    "\n",
    "#label folder\n",
    "label_path = '../../data/test/labels/'\n",
    "#list files in path\n",
    "files = os.listdir(label_path)\n",
    "#remove hidden files\n",
    "files = [file for file in files if not file.startswith('.')]\n",
    "print('Number of sessions:', len(files))\n",
    "\n",
    "\n",
    "for file in files:\n",
    "    #open the csv\n",
    "    label_df = pd.read_csv(label_path + file)\n",
    "    #get the session number\n",
    "    session = file.split('.')[0]\n",
    "    if session in train_val['session'].values:\n",
    "        #get the label\n",
    "        train_val_session = train_val[train_val['session'] == session]\n",
    "    else:\n",
    "        print('Session NOT in train_val:', session)\n",
    "        continue\n",
    "\n",
    "    #for each row in train_val_session, get the time, and match it to the time in the label dataset\n",
    "    #if the time is within the interval, get the label\n",
    "    for ind,row in label_df.iterrows():\n",
    "        time_min = row['Begin Time - ss.msec']\n",
    "        time_max = row['End Time - ss.msec']\n",
    "        #get labels for each\n",
    "        lab_uawk = row['UserAwkwardness']\n",
    "        lab_rmist = row['RobotMistake']\n",
    "        lab_irupt = row['InteractionRupture']\n",
    "        #get the rows in train_val_session that are within the interval\n",
    "        train_val_interval = train_val_session[(train_val_session['time'] >= time_min) & (train_val_session['time'] <= time_max)]\n",
    "        #get the indexes\n",
    "        index_interval = train_val_interval.index\n",
    "        print('lenght of train_val_interval:', len(train_val_interval))\n",
    "        print('index_interval:', index_interval)\n",
    "        if len(train_val_interval) == 0:\n",
    "            print('empty interval')\n",
    "            print('time_min:', time_min)\n",
    "            print('time_max:', time_max)\n",
    "            print('session:', session)\n",
    "        else:\n",
    "            if lab_uawk == 1:\n",
    "                train_val.loc[index_interval, 'UserAwkwardness'] = lab_uawk\n",
    "            if lab_rmist == 1:\n",
    "                train_val.loc[index_interval, 'RobotMistake'] = lab_rmist\n",
    "            if lab_irupt == 1:\n",
    "                train_val.loc[index_interval, 'InteractionRupture'] = lab_irupt\n",
    "\n",
    "\n",
    "\n",
    "train_val.to_csv('../../data/test.csv', index=False)\n",
    "train_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move label columns to positions 3-5\n",
    "cols = train_val.columns.tolist()\n",
    "cols = cols[:3] + cols[-3:] + cols[3:-3]\n",
    "train_val = train_val[cols]\n",
    "print(train_val.columns)\n",
    "print(train_val.shape)\n",
    "train_val.to_csv('../../data/test.csv', index=False)\n",
    "train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now normalize features\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "#get scaler \n",
    "scaler = joblib.load('../../data/scaler.pkl')\n",
    "\n",
    "#copy dataframe\n",
    "train_val_norm = train_val.copy()\n",
    "#normalize features\n",
    "features = train_val_norm.columns[6:]\n",
    "print(features)\n",
    "train_val_norm[features] = scaler.fit_transform(train_val_norm[features])\n",
    "\n",
    "#remove nan and inf\n",
    "train_val_norm.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "train_val_norm.dropna(inplace=True)\n",
    "\n",
    "\n",
    "train_val_norm.to_csv('../../data/test_norm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
